{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAI_keras_3.4영화리뷰분류.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D2rU4FF2vNZp",
        "mZ9SZes0vJZM",
        "LeEX7Ahu1Og0",
        "wwRLwHPf8xqF"
      ],
      "toc_visible": true,
      "mount_file_id": "1nTTD6nI1aqDikummy_9PkH8myP_9IBAd",
      "authorship_tag": "ABX9TyPcPm8us8H8/zVIzRp3pEKj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xhaktmchl/SAI_2020-2_keras_study/blob/main/SAI_keras_3_4%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2rU4FF2vNZp"
      },
      "source": [
        "###3.4영화 리뷰 분류\n",
        "\n",
        "###3.4.1 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzrHMLkFq3ax"
      },
      "source": [
        "import keras "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_xaKqjUrRu8",
        "outputId": "f1e19507-3234-4e49-ee94-b003ed95a7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data,train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) \n",
        "# num_words=10000 자주 나타나는 단어 10000개 뽑기\n",
        "# data= 리뷰, labels = 0부정, 1 긍정 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGG68vqUr1Pq",
        "outputId": "7370f88f-8bec-48a7-b86d-84cb03043cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data\n",
        "train_labels[0] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFTosYm5r7L3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ9SZes0vJZM"
      },
      "source": [
        "###3.4.2 데이터 준비\n",
        "\n",
        "신경망에 숫자 리스트 불가능=> 리스트를 텐서로 변환  \n",
        "\n",
        "1) 리스트에 패딩 추가해서 (samples, sequence_length) 크기의 정수 텐서로 변환  \n",
        "2) 원-핫 인코딩하여 0과 1의 벡터로 변환\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXQBy86mwUTa"
      },
      "source": [
        "# 숫자리스트를 벡터로 변환하기\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듦\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
        "    return results\n",
        "\n",
        "    # for i,v in enumerate() : 인덱스와 원소값 같이 튜플(,) 형태로 나옴\n",
        "\n",
        "   # 훈련 데이터를 벡터로 변환\n",
        "x_train = vectorize_sequences(train_data)\n",
        "   # 테스트 데이터를 벡터로 변환\n",
        "x_test = vectorize_sequences(test_data)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANTSQFu80Qje",
        "outputId": "97876823-1778-4530-9e4d-ee849efbd685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYCsh0mC06M_"
      },
      "source": [
        "# 레이블을 벡터로 바꿈\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeEX7Ahu1Og0"
      },
      "source": [
        "###3.4.3 신경망 모델 만들기\n",
        "\n",
        "- Dense 층에 전달한 매개변수(16)는 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다.     \n",
        "\n",
        "- 16개의 은닉 유닛이 있다는 것은 가중치 행렬 W의 크기가 (input_dimension, 16)이라는 뜻\n",
        "\n",
        "- 은닉 유닛의 개수를 늘리면 정확도 증가 , 하지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수 있음( 테스트 데이터에선 정확도 떨어질 수)  \n",
        "\n",
        "Dense 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요하다:\n",
        "\n",
        "- 얼마나 많은 층을 사용할 것인가  \n",
        "- 각 층에 얼마나 많은 은닉 유닛을 둘 것인가  \n",
        "\n",
        "보통 relu 함수 이용하지만\n",
        "여기선 감정을 0,1로 나타내서 시그모이드 함수 이용\n",
        "\n",
        "\n",
        "1) 신경말 모델  \n",
        "2개의 층(relu함수)- 마지막 (시그모이드 함수)=>0,1 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg17SdTW1LE6"
      },
      "source": [
        "# 모델 층 정의\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) #더한다 dense 층을 은닉유닛,relu함수,10000행 # //Q) 여기선 오류 안난다 ;; 뭐가 문제지\n",
        "model.add(layers.Dense(16, activation='relu')) \n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5RWehY28svg"
      },
      "source": [
        "다음은 모델정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxUlTnk16LD8"
      },
      "source": [
        "# 기본 모델 정의\n",
        "model.compile(optimizer='rmsprop', # 옵티마이저\n",
        "              loss='binary_crossentropy', # 확률 분포간의 차이를 측정\n",
        "              metrics=['accuracy']) # 정확도 지표"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjHYPFJg76St"
      },
      "source": [
        "옵티마이저의 매개변수 바꾸기 표현( Q) 아직은 잘 모르겠다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzv6DyJq7eSG"
      },
      "source": [
        "# 모델 정의1(옵티마이저 매개 변수 직접 )\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001), # 객체 만들어 전달\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4U795aL8Nmn"
      },
      "source": [
        "자신만의 손실함수, 측정함수 전달 표현( 표현이 있다는 것 정도만)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpACUmsg8T1S"
      },
      "source": [
        "# 모델정의 2 손실과 측정을  객체로 만들는 방법\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy, \n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwRLwHPf8xqF"
      },
      "source": [
        "### 훈련 검증\n",
        "\n",
        "모델정의 했으니 fit으로 훈련반복\n",
        "\n",
        "  하기 전 샘플을 가져와 모델을 검증한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndFP4jVFiupS"
      },
      "source": [
        "# 샘플로 모델 검증\n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O_NdSoKlP8w",
        "outputId": "21ce61dd-92fc-419e-b2ae-ae3c7ff906db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        }
      },
      "source": [
        "# fit 훈련 반복 ( 512개 샘플씩 20번 반복)\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.5463 - binary_accuracy: 0.7630 - val_loss: 0.4160 - val_binary_accuracy: 0.8657\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3288 - binary_accuracy: 0.8971 - val_loss: 0.3234 - val_binary_accuracy: 0.8796\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2322 - binary_accuracy: 0.9283 - val_loss: 0.2840 - val_binary_accuracy: 0.8882\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.1866 - binary_accuracy: 0.9404 - val_loss: 0.2855 - val_binary_accuracy: 0.8848\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1466 - binary_accuracy: 0.9550 - val_loss: 0.2790 - val_binary_accuracy: 0.8882\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1242 - binary_accuracy: 0.9618 - val_loss: 0.2895 - val_binary_accuracy: 0.8848\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1011 - binary_accuracy: 0.9696 - val_loss: 0.3080 - val_binary_accuracy: 0.8817\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0848 - binary_accuracy: 0.9765 - val_loss: 0.3840 - val_binary_accuracy: 0.8659\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0702 - binary_accuracy: 0.9816 - val_loss: 0.3569 - val_binary_accuracy: 0.8779\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0588 - binary_accuracy: 0.9845 - val_loss: 0.3664 - val_binary_accuracy: 0.8790\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0458 - binary_accuracy: 0.9887 - val_loss: 0.4044 - val_binary_accuracy: 0.8730\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0378 - binary_accuracy: 0.9919 - val_loss: 0.4243 - val_binary_accuracy: 0.8771\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0292 - binary_accuracy: 0.9943 - val_loss: 0.5219 - val_binary_accuracy: 0.8581\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0245 - binary_accuracy: 0.9951 - val_loss: 0.4956 - val_binary_accuracy: 0.8716\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0193 - binary_accuracy: 0.9966 - val_loss: 0.5239 - val_binary_accuracy: 0.8708\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0138 - binary_accuracy: 0.9985 - val_loss: 0.5584 - val_binary_accuracy: 0.8693\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0136 - binary_accuracy: 0.9972 - val_loss: 0.5908 - val_binary_accuracy: 0.8684\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0087 - binary_accuracy: 0.9992 - val_loss: 0.6210 - val_binary_accuracy: 0.8669\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0058 - binary_accuracy: 0.9998 - val_loss: 0.7375 - val_binary_accuracy: 0.8552\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0081 - binary_accuracy: 0.9983 - val_loss: 0.7051 - val_binary_accuracy: 0.8642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_4CN3MQlv4Q"
      },
      "source": [
        "model.fit() 메서드는 History 객체를 반환. history 속성은 모든 정보를 포함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHPSdq8_lvDd",
        "outputId": "ca359e8e-b28b-45e8-cd2f-739dc6c2a3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8hzf6PgmDG_"
      },
      "source": [
        "###matplotlib 시각화\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUmuoEqelvGi"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gCMhkF7ndWl"
      },
      "source": [
        "1.loss 함수의 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2tjrDQYmQVA",
        "outputId": "fd28a432-f458-43fd-d7e1-b75613e17dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "acc = history.history['acc'] # history 객체에서 data 정확도 저장 //Q) acc 오류남 업데이트 되서 다른 버전인듯\n",
        "val_acc = history.history['val_acc'] # history 에서 label 정확도 저장\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# 매틀랩이랑 비슷\n",
        "# ‘bo’는 파란색 점을 의미합니다\n",
        "#  x,y축 과 이름 달기\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss') \n",
        "# ‘b’는 파란색 실선을 의미합니다\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5f0155c5f42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# history 객체에서 data 정확도 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# history 에서 label 정확도 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZXZHN0Kx_nK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gR7UmI2nWf6"
      },
      "source": [
        "2. 정확도(acc)의 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLORDdqWnu3S"
      },
      "source": [
        "plt.clf()   # 그래프를 초기화합니다\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izy7WI_8xWyL"
      },
      "source": [
        "### 그래프의 해석\n",
        "각 표의 점선은 훈련 손실과 훈련 정확도이고   \n",
        "실선은 훈련검증의 손실과 정확도이다.\n",
        "\n",
        "훈련 손실은 최소화되고 정확도는 점점 증가하므로 훈련데이터는 잘 학습.   \n",
        "하지만 검증 손실은 증가하고 검증 정혹도는 낮아지므로 훈련데이터에서만 잘 학습  => 오버피팅(과대적합) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dilt7Cf-y6TG"
      },
      "source": [
        "### 과대적합 해결\n",
        "\n",
        ": 모델 초기화 후 4번의 에포크만 학습 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTuXJr20y5d4"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', # 최적화\n",
        "              loss='binary_crossentropy', # 크로스 엔트로피 손실함수 (확률을 구할때 효과적)\n",
        "              metrics=['accuracy']) \n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512) # 4번만 학습\n",
        "results = model.evaluate(x_test, y_test) # 모델 평가"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhWGNepcz6Mc"
      },
      "source": [
        "# 결과 출력\n",
        "results "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmq7ZE6N0KkS"
      },
      "source": [
        "결과 : 모델정확도 증가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxAT2pge06po"
      },
      "source": [
        "### 훈련된 모델로 새로운 데이터 예측\n",
        ": predict 모듈사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BidYp7S-05LB"
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxQi-m571Cpg"
      },
      "source": [
        "###정리\n",
        "\n",
        "- 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있음\n",
        "\n",
        "- 과대적합 조심 -> 훈련세트이 이외의 데이터로 성능 모니터링\n",
        "\n",
        "- 이진분류 문제 => 유닛 +  마지막에 sigmoid 활성화 함수를 가진 dense층으로 해야함 -> sigmoid 활성화 함수의 손실함수는 binary_crossentropy .\n"
      ]
    }
  ]
}